{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Sentiment Analysis and Naive Bayes\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In the sentiment analysis lesson, we used a predefined dictionary of positive and negative valences for words. This  lab inverts that process: You'll find which words are most likely to appear in positive or negative reviews by using the rotten versus fresh binary label.\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "A common practical way to do this is with the Naive Bayes algorithm. Naive Bayes classifiers are covered in more depth in another lecture â€” for this lab, you'll just be leveraging the scikit-learn implementation.\n",
    "\n",
    "Given a feature, $x_i$, and target, $y_i$, Naive Bayes classifiers solve for $P(x_i \\;|\\; y_i)$. In other words, they solve for the probability of a feature/predictor _given_ that the target is one.\n",
    "\n",
    "We'll use this to figure out which words are more likely to appear when the target is one (\"fresh\") versus zero (\"rotten\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1) Load the packages and movie data.\n",
    "\n",
    "Perform any necessary cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We are using the BernoulliNB version of Naive Bayes, which assumes that predictors are binary encoded.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pd.read_csv('./datasets/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709.0        Time Out   \n",
       "1     Richard Corliss  fresh  114709.0   TIME Magazine   \n",
       "2         David Ansen  fresh  114709.0        Newsweek   \n",
       "3       Leonard Klady  fresh  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709.0  Chicago Reader   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "rt['qt'] = rt['quote'].map(lambda x: x.translate(None, string.punctuation).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt['quote_len'] = rt['quote'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = rt[(rt['fresh'] != 'none') & (rt['quote_len']>10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Create a predictor matrix of words in the quotes with `CountVectorizer`.\n",
    "\n",
    "It's up to you to select an n-gram range. **Make sure that `binary=True`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "pclass = Pipeline([\n",
    "    ('vect', CountVectorizer(strip_accents='unicode', binary=True, stop_words='english', ngram_range=(1,3), min_df=2)),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('cls', MultinomialNB())\n",
    "#     ('logit', LogisticRegression())\n",
    "    ('bnb', BernoulliNB())\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = rt['qt']\n",
    "y = rt['fresh']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42) #can add in stratify=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73684211, 0.7676182 , 0.74130241, 0.73806336, 0.75457385])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(pclass, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and predict\n",
    "class_pred = class_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fresh  rotten\n",
      "fresh    1488     230\n",
      "rotten    469     615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      fresh       0.76      0.87      0.81      1718\n",
      "     rotten       0.73      0.57      0.64      1084\n",
      "\n",
      "avg / total       0.75      0.75      0.74      2802\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7237159996191322"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "conmat = np.array(confusion_matrix(y_test, class_pred))\n",
    "confusion = pd.DataFrame(conmat, index=['fresh','rotten'], columns=['fresh','rotten'])\n",
    "print (confusion)\n",
    "print (classification_report(y_test, class_pred))\n",
    "metrics.f1_score(y_test, class_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3) Split the data into training and testing sets.\n",
    "\n",
    "You should keep 25 percent of the data in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X2 = X.drop('y',axis=1)\n",
    "y2 = X['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, stratify=y2, test_size=0.2, random_state=42) #can add in stratify=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4) Build a `BernoulliNB` model predicting fresh versus rotten from the word occurrences.\n",
    "\n",
    "The model should only be built (and cross-validated) on the training data.\n",
    "\n",
    "Cross-validate the score and compare it to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fresh     0.612955\n",
       "rotten    0.387045\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5) Pull out the probability of words given \"fresh.\"\n",
    "\n",
    "The `.feature_log_prob_` attribute of the Naive Bayes model contains the log probabilities of a feature appearing given a target class.\n",
    "\n",
    "The rows correspond to the class of the target and the columns correspond to the features. The first row is the zero, \"rotten\" class and the second row is the one, \"fresh\" class.\n",
    "\n",
    "#### 5.A) Pull out the log probabilities and convert them to probabilities for fresh and rotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing text into dataframe\n",
    "cvt      =  CountVectorizer(strip_accents='unicode', binary=True, stop_words='english', ngram_range=(1,3), min_df=2)\n",
    "X_train2 = pd.DataFrame(cvt.fit_transform(X_train).todense(),\n",
    "             columns=cvt.get_feature_names())#binary=True if BernoulliNB version of Naive Bayes is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model fit\n",
    "bnb = BernoulliNB()\n",
    "model = bnb.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73550401, 0.76895629, 0.74308653, 0.73493976, 0.73717091])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternative model cross_val direct\n",
    "cross_val_score(bnb, X_train2, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize test set, transform directly\n",
    "X_test2 = pd.DataFrame(cvt.transform(X_test).todense(),\n",
    "             columns=cvt.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7505353319057816"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score vs baseline 0.61\n",
    "model.score(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>exp_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>film</td>\n",
       "      <td>-1.939528</td>\n",
       "      <td>14.377183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>movie</td>\n",
       "      <td>-2.116197</td>\n",
       "      <td>12.048894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>like</td>\n",
       "      <td>-3.165330</td>\n",
       "      <td>4.220023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>story</td>\n",
       "      <td>-3.175728</td>\n",
       "      <td>4.176368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>best</td>\n",
       "      <td>-3.186236</td>\n",
       "      <td>4.132712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>good</td>\n",
       "      <td>-3.222082</td>\n",
       "      <td>3.987194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>films</td>\n",
       "      <td>-3.263056</td>\n",
       "      <td>3.827125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9804</th>\n",
       "      <td>movies</td>\n",
       "      <td>-3.274529</td>\n",
       "      <td>3.783469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>comedy</td>\n",
       "      <td>-3.358747</td>\n",
       "      <td>3.477881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14738</th>\n",
       "      <td>time</td>\n",
       "      <td>-3.410260</td>\n",
       "      <td>3.303260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1      exp_0\n",
       "5245     film -1.939528  14.377183\n",
       "9606    movie -2.116197  12.048894\n",
       "8451     like -3.165330   4.220023\n",
       "13848   story -3.175728   4.176368\n",
       "1305     best -3.186236   4.132712\n",
       "6257     good -3.222082   3.987194\n",
       "5447    films -3.263056   3.827125\n",
       "9804   movies -3.274529   3.783469\n",
       "2647   comedy -3.358747   3.477881\n",
       "14738    time -3.410260   3.303260"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is for fresh class, cos didnt encode y\n",
    "coef_0 = pd.DataFrame(zip(X_train2.columns, model.feature_log_prob_[0]))\n",
    "coef_0['exp_0'] = np.exp(coef_0[1])*100\n",
    "coef_0.sort_values('exp_0', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>exp_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>movie</td>\n",
       "      <td>-2.007442</td>\n",
       "      <td>13.433180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>film</td>\n",
       "      <td>-2.318846</td>\n",
       "      <td>9.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>like</td>\n",
       "      <td>-2.709203</td>\n",
       "      <td>6.658986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13848</th>\n",
       "      <td>story</td>\n",
       "      <td>-3.149883</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>just</td>\n",
       "      <td>-3.251666</td>\n",
       "      <td>3.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>comedy</td>\n",
       "      <td>-3.313035</td>\n",
       "      <td>3.640553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8563</th>\n",
       "      <td>little</td>\n",
       "      <td>-3.405816</td>\n",
       "      <td>3.317972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>characters</td>\n",
       "      <td>-3.405816</td>\n",
       "      <td>3.317972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9804</th>\n",
       "      <td>movies</td>\n",
       "      <td>-3.419803</td>\n",
       "      <td>3.271889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>good</td>\n",
       "      <td>-3.441156</td>\n",
       "      <td>3.202765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1      exp_1\n",
       "9606        movie -2.007442  13.433180\n",
       "5245         film -2.318846   9.838710\n",
       "8451         like -2.709203   6.658986\n",
       "13848       story -3.149883   4.285714\n",
       "7935         just -3.251666   3.870968\n",
       "2647       comedy -3.313035   3.640553\n",
       "8563       little -3.405816   3.317972\n",
       "2227   characters -3.405816   3.317972\n",
       "9804       movies -3.419803   3.271889\n",
       "6257         good -3.441156   3.202765"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_1 = pd.DataFrame(zip(X_train2.columns, model.feature_log_prob_[1]))\n",
    "coef_1['exp_1'] = np.exp(coef_1[1])*100\n",
    "coef_1.sort_values('exp_1', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.B) Make a DataFrame with the probabilities and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>exp_0</th>\n",
       "      <th>exp_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007</td>\n",
       "      <td>0.087311</td>\n",
       "      <td>0.046083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.145518</td>\n",
       "      <td>0.391705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 minutes</td>\n",
       "      <td>0.043655</td>\n",
       "      <td>0.138249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 years</td>\n",
       "      <td>0.043655</td>\n",
       "      <td>0.069124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.101863</td>\n",
       "      <td>0.069124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     exp_0     exp_1\n",
       "0         007  0.087311  0.046083\n",
       "1          10  0.145518  0.391705\n",
       "2  10 minutes  0.043655  0.138249\n",
       "3    10 years  0.043655  0.069124\n",
       "4         100  0.101863  0.069124"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob = pd.concat([coef_0[[0,'exp_0']], coef_1['exp_1']], axis=1)\n",
    "df_prob.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.C) Create a column that is the difference between the probability of the appearance of fresh and rotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fresh is 0 cos nv encode\n",
    "df_prob['diff'] = df_prob['exp_0'] - df_prob['exp_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.D) Look at the most likely words for fresh and rotten reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>exp_0</th>\n",
       "      <th>exp_1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>film</td>\n",
       "      <td>14.377183</td>\n",
       "      <td>9.838710</td>\n",
       "      <td>4.538473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>best</td>\n",
       "      <td>4.132712</td>\n",
       "      <td>1.543779</td>\n",
       "      <td>2.588934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>great</td>\n",
       "      <td>2.721187</td>\n",
       "      <td>0.875576</td>\n",
       "      <td>1.845611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>performance</td>\n",
       "      <td>2.182771</td>\n",
       "      <td>0.506912</td>\n",
       "      <td>1.675858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>entertaining</td>\n",
       "      <td>2.182771</td>\n",
       "      <td>0.622120</td>\n",
       "      <td>1.560651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>films</td>\n",
       "      <td>3.827125</td>\n",
       "      <td>2.373272</td>\n",
       "      <td>1.453853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>fun</td>\n",
       "      <td>2.473807</td>\n",
       "      <td>1.244240</td>\n",
       "      <td>1.229567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>1.775320</td>\n",
       "      <td>0.552995</td>\n",
       "      <td>1.222325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>american</td>\n",
       "      <td>2.022701</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.216249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16204</th>\n",
       "      <td>years</td>\n",
       "      <td>1.848079</td>\n",
       "      <td>0.668203</td>\n",
       "      <td>1.179876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0      exp_0     exp_1      diff\n",
       "5245            film  14.377183  9.838710  4.538473\n",
       "1305            best   4.132712  1.543779  2.588934\n",
       "6403           great   2.721187  0.875576  1.845611\n",
       "10783    performance   2.182771  0.506912  1.675858\n",
       "4600    entertaining   2.182771  0.622120  1.560651\n",
       "5447           films   3.827125  2.373272  1.453853\n",
       "5882             fun   2.473807  1.244240  1.229567\n",
       "4618   entertainment   1.775320  0.552995  1.222325\n",
       "593         american   2.022701  0.806452  1.216249\n",
       "16204          years   1.848079  0.668203  1.179876"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#likely fresh words\n",
    "df_prob.sort_values('diff', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>exp_0</th>\n",
       "      <th>exp_1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>like</td>\n",
       "      <td>4.220023</td>\n",
       "      <td>6.658986</td>\n",
       "      <td>-2.438963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>bad</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>2.557604</td>\n",
       "      <td>-1.771806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8563</th>\n",
       "      <td>little</td>\n",
       "      <td>1.818976</td>\n",
       "      <td>3.317972</td>\n",
       "      <td>-1.498997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>doesnt</td>\n",
       "      <td>1.600698</td>\n",
       "      <td>3.064516</td>\n",
       "      <td>-1.463818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>movie</td>\n",
       "      <td>12.048894</td>\n",
       "      <td>13.433180</td>\n",
       "      <td>-1.384286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11774</th>\n",
       "      <td>really</td>\n",
       "      <td>0.698487</td>\n",
       "      <td>2.050691</td>\n",
       "      <td>-1.352205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>isnt</td>\n",
       "      <td>1.251455</td>\n",
       "      <td>2.511521</td>\n",
       "      <td>-1.260066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11031</th>\n",
       "      <td>plot</td>\n",
       "      <td>1.266007</td>\n",
       "      <td>2.465438</td>\n",
       "      <td>-1.199431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14543</th>\n",
       "      <td>theres</td>\n",
       "      <td>1.775320</td>\n",
       "      <td>2.949309</td>\n",
       "      <td>-1.173989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>just</td>\n",
       "      <td>2.706636</td>\n",
       "      <td>3.870968</td>\n",
       "      <td>-1.164332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      exp_0      exp_1      diff\n",
       "8451     like   4.220023   6.658986 -2.438963\n",
       "1069      bad   0.785797   2.557604 -1.771806\n",
       "8563   little   1.818976   3.317972 -1.498997\n",
       "4023   doesnt   1.600698   3.064516 -1.463818\n",
       "9606    movie  12.048894  13.433180 -1.384286\n",
       "11774  really   0.698487   2.050691 -1.352205\n",
       "7674     isnt   1.251455   2.511521 -1.260066\n",
       "11031    plot   1.266007   2.465438 -1.199431\n",
       "14543  theres   1.775320   2.949309 -1.173989\n",
       "7935     just   2.706636   3.870968 -1.164332"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#likely rotten words\n",
    "df_prob.sort_values('diff', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6) Examine how your model performs on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7505353319057816"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score vs baseline 0.61\n",
    "model.score(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7) Look at the top 10 movies and reviews likely to be fresh and the top 10 likely to be rotten.\n",
    "\n",
    "You can fit the model on the full set of data for this.\n",
    "\n",
    "> **Note:** While it's good at classifying, Naive Bayes is known to be somewhat bad at providing accurate predicted probabilities (beyond getting it on the correct side of 50 percent). It's a good classifier but a bad estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97158038, 0.90979675, 0.00333308, ..., 0.79236212, 0.01529337,\n",
       "       0.88559509])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(X_test).reset_index()\n",
    "test['fresh_prob'] = y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rudy vallee turns in his best performance as a gentle puny millionaire named hackensacker in this brilliant simultaneously tender and scalding 1942 screwball comedy by preston sturges',\n",
       "       'the city of lost children is a stunningly surreal fantasy a fable of longing and danger of heroic deeds and bravery set in a brilliantly realized world of its own it is one of the most audacious original films of the year',\n",
       "       'martin scorseses intimate epic about money sex and brute force is a grandly conceived study of what happens to goodfellas from the mean streets when they outstrip their wildest dreams and achieve the pinnacle of wealth and power',\n",
       "       'the most exciting debut in years it is unified by the extraordinary decor  colour supplement chic meets pop art surrealism  which creates a world of totally fantastic reality situated foursquare in contemporary paris',\n",
       "       'james and the giant peach the latest animated film from disney is a technological marvel arch and innovative with a daringly offbeat visual conception but its also a strenuously artful film with a macabre edge that may scare small children',\n",
       "       'the walt disney animators returned to top form with this beautifully crafted and wonderfully expressive cartoon feature the first major work to come out of the disney studios in a decade',\n",
       "       'where the wild things are is a fiercely innovative film with surprising texture and nuance it captures the joy and exuberance of childhood without shying away from its very real pains and woes',\n",
       "       'all of the performances are firstrate pesci stands out though with his seemingly unscripted manner goodfellas is easily one of the years best films',\n",
       "       'all quiet on the western front is the definitive world war i motion picture the best of a surprisingly small class of movies',\n",
       "       'mr cameron has made a swift exciting specialeffects epic that thoroughly justifies its vast expense and greatly improves upon the first films potent but rudimentary visual style'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 likely fresh\n",
    "test.sort_values('fresh_prob', ascending=False).head(10)['qt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the problem with deuce bigalow male gigolo is the low level of its low humor',\n",
       "       'georgia rule is a bad idea dreadfully executed  on golden pond with fellatio jokes and whimsical incest melodrama and fonda playing her dad who more and more she eerily resembles',\n",
       "       'contrived obvious and overstated crash is basically just one white mans righteous attempt to make other white people feel as if theyve confronted the problem of racism headon',\n",
       "       'while the makers of robin hood prince of thieves may have set out to bury the poor old duffer of sherwood forest in a welter of trendy banter they have ended up burying themselves as well',\n",
       "       'bland interminable chase scenes take up so much of the story  the hackneyed plot doesnt need much exposition  that the sheer repetitiveness begins to amaze you',\n",
       "       'perhaps at 90 or so minutes it would have been the hitchcockian thriller that it isnt at the beginning but turns into at two hours and 20 minutes theres too much of the film that feels like reiteration',\n",
       "       'more of a cinematic joke book than a real movie spy hard hits you with gags faster than henny youngman on speed even when individual bits misfire the unrelenting barrage of silliness can break down your resistance',\n",
       "       'if universal soldier the return isnt the dullest most derivative unimaginative noisy repetitive mindnumbing and generally imbecilic movie of the year its not because director mic rodgers wasnt trying hard enough',\n",
       "       'do not take your mom to georgia rule unless shes roseanne barr you may expect a threegenerational chick flick but what you get is a childrape comedy',\n",
       "       'unfortunately the movie is so busy crosspolinating its genres that it never pauses for the kind of thought that might have made it really special instead of just fitfully funny'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 likely rot\n",
    "test.sort_values('fresh_prob', ascending=True).head(10)['qt'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8) Find the movies with at least 10 reviews that are most likely to be fresh or rotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
