{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Sentiment Analysis and Naive Bayes\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In the sentiment analysis lesson, we used a predefined dictionary of positive and negative valences for words. This  lab inverts that process: You'll find which words are most likely to appear in positive or negative reviews by using the rotten versus fresh binary label.\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "A common practical way to do this is with the Naive Bayes algorithm. Naive Bayes classifiers are covered in more depth in another lecture â€” for this lab, you'll just be leveraging the scikit-learn implementation.\n",
    "\n",
    "Given a feature, $x_i$, and target, $y_i$, Naive Bayes classifiers solve for $P(x_i \\;|\\; y_i)$. In other words, they solve for the probability of a feature/predictor _given_ that the target is one.\n",
    "\n",
    "We'll use this to figure out which words are more likely to appear when the target is one (\"fresh\") versus zero (\"rotten\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1) Load the packages and movie data.\n",
    "\n",
    "Perform any necessary cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We are using the BernoulliNB version of Naive Bayes, which assumes that predictors are binary encoded.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pd.read_csv('./datasets/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709.0        Time Out   \n",
       "1     Richard Corliss  fresh  114709.0   TIME Magazine   \n",
       "2         David Ansen  fresh  114709.0        Newsweek   \n",
       "3       Leonard Klady  fresh  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709.0  Chicago Reader   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "rt['qt'] = rt['quote'].map(lambda x: x.translate(None, string.punctuation).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt['quote_len'] = rt['quote'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = rt[(rt['fresh'] != 'none') & (rt['quote_len']>10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Create a predictor matrix of words in the quotes with `CountVectorizer`.\n",
    "\n",
    "It's up to you to select an n-gram range. **Make sure that `binary=True`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "pclass = Pipeline([\n",
    "    ('vect', CountVectorizer(strip_accents='unicode', binary=True, stop_words='english', ngram_range=(1,3), min_df=2)),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('cls', MultinomialNB())\n",
    "#     ('logit', LogisticRegression())\n",
    "    ('bnb', BernoulliNB())\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = rt['qt']\n",
    "y = rt['fresh']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42) #can add in stratify=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73684211, 0.7676182 , 0.74130241, 0.73806336, 0.75457385])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(pclass, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and predict\n",
    "class_pred = class_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fresh  rotten\n",
      "fresh    1488     230\n",
      "rotten    469     615\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      fresh       0.76      0.87      0.81      1718\n",
      "     rotten       0.73      0.57      0.64      1084\n",
      "\n",
      "avg / total       0.75      0.75      0.74      2802\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7237159996191322"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "conmat = np.array(confusion_matrix(y_test, class_pred))\n",
    "confusion = pd.DataFrame(conmat, index=['fresh','rotten'], columns=['fresh','rotten'])\n",
    "print (confusion)\n",
    "print (classification_report(y_test, class_pred))\n",
    "metrics.f1_score(y_test, class_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3) Split the data into training and testing sets.\n",
    "\n",
    "You should keep 25 percent of the data in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X2 = X.drop('y',axis=1)\n",
    "y2 = X['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, stratify=y2, test_size=0.2, random_state=42) #can add in stratify=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4) Build a `BernoulliNB` model predicting fresh versus rotten from the word occurrences.\n",
    "\n",
    "The model should only be built (and cross-validated) on the training data.\n",
    "\n",
    "Cross-validate the score and compare it to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fresh     0.612955\n",
       "rotten    0.387045\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5) Pull out the probability of words given \"fresh.\"\n",
    "\n",
    "The `.feature_log_prob_` attribute of the Naive Bayes model contains the log probabilities of a feature appearing given a target class.\n",
    "\n",
    "The rows correspond to the class of the target and the columns correspond to the features. The first row is the zero, \"rotten\" class and the second row is the one, \"fresh\" class.\n",
    "\n",
    "#### 5.A) Pull out the log probabilities and convert them to probabilities for fresh and rotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing text into dataframe\n",
    "cvt      =  CountVectorizer(strip_accents='unicode', binary=True, stop_words='english', ngram_range=(1,1), min_df=2)\n",
    "X_train2 = pd.DataFrame(cvt.fit_transform(X_train).todense(),\n",
    "             columns=cvt.get_feature_names())#binary=True if BernoulliNB version of Naive Bayes is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model fit\n",
    "bnb = BernoulliNB()\n",
    "model = bnb.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7381802 , 0.77430865, 0.7528992 , 0.74564926, 0.75412762])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternative model cross_val direct\n",
    "cross_val_score(bnb, X_train2, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize test set, transform directly\n",
    "X_test2 = pd.DataFrame(cvt.transform(X_test).todense(),\n",
    "             columns=cvt.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7530335474660956"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score vs baseline 0.61\n",
    "model.score(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6626df416189>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#this is for fresh class, cos didnt encode y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcoef_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcoef_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'exp_0'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcoef_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exp_0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#this is for fresh class, cos didnt encode y\n",
    "coef_0 = pd.DataFrame(zip(X_train2.columns, model.feature_log_prob_[0]))\n",
    "coef_0['exp_0'] = np.exp(coef_0[1])*100\n",
    "coef_0.sort_values('exp_0', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>exp_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>movie</td>\n",
       "      <td>-2.007442</td>\n",
       "      <td>13.433180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>film</td>\n",
       "      <td>-2.318846</td>\n",
       "      <td>9.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>like</td>\n",
       "      <td>-2.709203</td>\n",
       "      <td>6.658986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9111</th>\n",
       "      <td>story</td>\n",
       "      <td>-3.149883</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>just</td>\n",
       "      <td>-3.251666</td>\n",
       "      <td>3.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>comedy</td>\n",
       "      <td>-3.313035</td>\n",
       "      <td>3.640553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>little</td>\n",
       "      <td>-3.405816</td>\n",
       "      <td>3.317972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>characters</td>\n",
       "      <td>-3.405816</td>\n",
       "      <td>3.317972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>movies</td>\n",
       "      <td>-3.419803</td>\n",
       "      <td>3.271889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>good</td>\n",
       "      <td>-3.441156</td>\n",
       "      <td>3.202765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1      exp_1\n",
       "6224       movie -2.007442  13.433180\n",
       "3553        film -2.318846   9.838710\n",
       "5536        like -2.709203   6.658986\n",
       "9111       story -3.149883   4.285714\n",
       "5218        just -3.251666   3.870968\n",
       "1812      comedy -3.313035   3.640553\n",
       "5582      little -3.405816   3.317972\n",
       "1532  characters -3.405816   3.317972\n",
       "6232      movies -3.419803   3.271889\n",
       "4089        good -3.441156   3.202765"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_1 = pd.DataFrame(zip(X_train2.columns, model.feature_log_prob_[1]))\n",
    "coef_1['exp_1'] = np.exp(coef_1[1])*100\n",
    "coef_1.sort_values('exp_1', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.B) Make a DataFrame with the probabilities and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>exp_0</th>\n",
       "      <th>exp_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007</td>\n",
       "      <td>0.087311</td>\n",
       "      <td>0.046083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.145518</td>\n",
       "      <td>0.391705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.101863</td>\n",
       "      <td>0.069124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>0.058207</td>\n",
       "      <td>0.046083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>0.046083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     exp_0     exp_1\n",
       "0   007  0.087311  0.046083\n",
       "1    10  0.145518  0.391705\n",
       "2   100  0.101863  0.069124\n",
       "3   101  0.058207  0.046083\n",
       "4  10th  0.029104  0.046083"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob = pd.concat([coef_0[[0,'exp_0']], coef_1['exp_1']], axis=1)\n",
    "df_prob.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.C) Create a column that is the difference between the probability of the appearance of fresh and rotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fresh is 0 cos nv encode\n",
    "df_prob['diff'] = df_prob['exp_0'] - df_prob['exp_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.D) Look at the most likely words for fresh and rotten reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>exp_0</th>\n",
       "      <th>exp_1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>film</td>\n",
       "      <td>14.377183</td>\n",
       "      <td>9.838710</td>\n",
       "      <td>4.538473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>best</td>\n",
       "      <td>4.132712</td>\n",
       "      <td>1.543779</td>\n",
       "      <td>2.588934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>great</td>\n",
       "      <td>2.721187</td>\n",
       "      <td>0.875576</td>\n",
       "      <td>1.845611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>performance</td>\n",
       "      <td>2.182771</td>\n",
       "      <td>0.506912</td>\n",
       "      <td>1.675858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>entertaining</td>\n",
       "      <td>2.182771</td>\n",
       "      <td>0.622120</td>\n",
       "      <td>1.560651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>films</td>\n",
       "      <td>3.827125</td>\n",
       "      <td>2.373272</td>\n",
       "      <td>1.453853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>fun</td>\n",
       "      <td>2.473807</td>\n",
       "      <td>1.244240</td>\n",
       "      <td>1.229567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>1.775320</td>\n",
       "      <td>0.552995</td>\n",
       "      <td>1.222325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>american</td>\n",
       "      <td>2.022701</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.216249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10694</th>\n",
       "      <td>years</td>\n",
       "      <td>1.848079</td>\n",
       "      <td>0.668203</td>\n",
       "      <td>1.179876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0      exp_0     exp_1      diff\n",
       "3553            film  14.377183  9.838710  4.538473\n",
       "930             best   4.132712  1.543779  2.588934\n",
       "4161           great   2.721187  0.875576  1.845611\n",
       "6894     performance   2.182771  0.506912  1.675858\n",
       "3120    entertaining   2.182771  0.622120  1.560651\n",
       "3560           films   3.827125  2.373272  1.453853\n",
       "3866             fun   2.473807  1.244240  1.229567\n",
       "3122   entertainment   1.775320  0.552995  1.222325\n",
       "418         american   2.022701  0.806452  1.216249\n",
       "10694          years   1.848079  0.668203  1.179876"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#likely fresh words\n",
    "df_prob.sort_values('diff', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>exp_0</th>\n",
       "      <th>exp_1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>like</td>\n",
       "      <td>4.220023</td>\n",
       "      <td>6.658986</td>\n",
       "      <td>-2.438963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>bad</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>2.557604</td>\n",
       "      <td>-1.771806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>little</td>\n",
       "      <td>1.818976</td>\n",
       "      <td>3.317972</td>\n",
       "      <td>-1.498997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>doesnt</td>\n",
       "      <td>1.600698</td>\n",
       "      <td>3.064516</td>\n",
       "      <td>-1.463818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>movie</td>\n",
       "      <td>12.048894</td>\n",
       "      <td>13.433180</td>\n",
       "      <td>-1.384286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>really</td>\n",
       "      <td>0.698487</td>\n",
       "      <td>2.050691</td>\n",
       "      <td>-1.352205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>isnt</td>\n",
       "      <td>1.251455</td>\n",
       "      <td>2.511521</td>\n",
       "      <td>-1.260066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>plot</td>\n",
       "      <td>1.266007</td>\n",
       "      <td>2.465438</td>\n",
       "      <td>-1.199431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587</th>\n",
       "      <td>theres</td>\n",
       "      <td>1.775320</td>\n",
       "      <td>2.949309</td>\n",
       "      <td>-1.173989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>just</td>\n",
       "      <td>2.706636</td>\n",
       "      <td>3.870968</td>\n",
       "      <td>-1.164332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      exp_0      exp_1      diff\n",
       "5536    like   4.220023   6.658986 -2.438963\n",
       "767      bad   0.785797   2.557604 -1.771806\n",
       "5582  little   1.818976   3.317972 -1.498997\n",
       "2757  doesnt   1.600698   3.064516 -1.463818\n",
       "6224   movie  12.048894  13.433180 -1.384286\n",
       "7592  really   0.698487   2.050691 -1.352205\n",
       "5075    isnt   1.251455   2.511521 -1.260066\n",
       "7051    plot   1.266007   2.465438 -1.199431\n",
       "9587  theres   1.775320   2.949309 -1.173989\n",
       "5218    just   2.706636   3.870968 -1.164332"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#likely rotten words\n",
    "df_prob.sort_values('diff', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6) Examine how your model performs on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7530335474660956"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score vs baseline 0.61\n",
    "model.score(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7) Look at the top 10 movies and reviews likely to be fresh and the top 10 likely to be rotten.\n",
    "\n",
    "You can fit the model on the full set of data for this.\n",
    "\n",
    "> **Note:** While it's good at classifying, Naive Bayes is known to be somewhat bad at providing accurate predicted probabilities (beyond getting it on the correct side of 50 percent). It's a good classifier but a bad estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97892562, 0.89027705, 0.16938948, ..., 0.74412143, 0.03617104,\n",
       "       0.90330904])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(X_test).reset_index()\n",
    "test['fresh_prob'] = y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rudy vallee turns in his best performance as a gentle puny millionaire named hackensacker in this brilliant simultaneously tender and scalding 1942 screwball comedy by preston sturges',\n",
       "       'the most exciting debut in years it is unified by the extraordinary decor  colour supplement chic meets pop art surrealism  which creates a world of totally fantastic reality situated foursquare in contemporary paris',\n",
       "       'the city of lost children is a stunningly surreal fantasy a fable of longing and danger of heroic deeds and bravery set in a brilliantly realized world of its own it is one of the most audacious original films of the year',\n",
       "       'where the wild things are is a fiercely innovative film with surprising texture and nuance it captures the joy and exuberance of childhood without shying away from its very real pains and woes',\n",
       "       'martin scorseses intimate epic about money sex and brute force is a grandly conceived study of what happens to goodfellas from the mean streets when they outstrip their wildest dreams and achieve the pinnacle of wealth and power',\n",
       "       'this is one of the years most unabashed and powerful love stories using flawless performances intelligent dialogue crisp camera work and loaded glances to attain a level of eroticism and emotional connection that many similar films miss',\n",
       "       'the walt disney animators returned to top form with this beautifully crafted and wonderfully expressive cartoon feature the first major work to come out of the disney studios in a decade',\n",
       "       'a shrewd political observer for decades beatty has fashioned a hilarious morality tale that delivers a surprisingly potent angry message beneath the laughs',\n",
       "       'sumptuous haunting and unusually tender a nakedly psychological in to bergmans earliest artistic impulses nothing else in his oeuvre addresses so directly his childhood escapes into fantasy as the byproduct of a harsh lutheran upbringing',\n",
       "       'mr cameron has made a swift exciting specialeffects epic that thoroughly justifies its vast expense and greatly improves upon the first films potent but rudimentary visual style'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 likely fresh\n",
    "test.sort_values('fresh_prob', ascending=False).head(10)['qt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bland interminable chase scenes take up so much of the story  the hackneyed plot doesnt need much exposition  that the sheer repetitiveness begins to amaze you',\n",
       "       'as you sit through the interminable twohoursplus that constitute the fifth element  a colossally stupid overbearingly pompous new movie by luc besson  you can expect to become acquainted with boredom on the most elemental level',\n",
       "       'georgia rule is a bad idea dreadfully executed  on golden pond with fellatio jokes and whimsical incest melodrama and fonda playing her dad who more and more she eerily resembles',\n",
       "       'with a cigar box of subplots this episodic yarn is more numbing than boring though its increasingly compelling narrative has the illtimed misfortune to collapse completely in its final talky segment',\n",
       "       'if universal soldier the return isnt the dullest most derivative unimaginative noisy repetitive mindnumbing and generally imbecilic movie of the year its not because director mic rodgers wasnt trying hard enough',\n",
       "       'being an appealing shallow goofoff can wear thin and shore seems incapable of carrying a movie even when its a 90minute knockoff like this',\n",
       "       'unfortunately overblown production just pumps hot air in too many directions and comes up limp',\n",
       "       'after a promising start omega code devolves into chase after chase cliche after cliche until youve finally forgotten just what it is that darn old codes supposed to do in the first place',\n",
       "       'like so many postval lewton horror films this 1992 feature starts out promisingly while the plot is mainly a matter of suggestion but gradually turns gross and obvious as the meanings become literal and unambiguous',\n",
       "       'using talent of this order on a script this weak along with merely decorative appearances by the likes of lauren bacall and wilford brimley amounts to the hollywood equivalent of government waste'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 likely rot\n",
    "test.sort_values('fresh_prob', ascending=True).head(10)['qt'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8) Find the movies with at least 10 reviews that are most likely to be fresh or rotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
