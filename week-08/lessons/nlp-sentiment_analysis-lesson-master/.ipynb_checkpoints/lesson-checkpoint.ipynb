{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Sentiment Analysis With SpaCy and VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Sentiment Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## SpaCy and Part of Speech (PoS)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "  Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages\n",
      "Requirement already satisfied: spacy>=2.0.0a18 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.1 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: pathlib in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: ujson>=1.35 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: regex==2017.4.5 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: cytoolz<0.9,>=0.8 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: msgpack-python in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: msgpack-numpy==0.4.1 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: pyreadline>=1.7.1 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from dill<0.3,>=0.2->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\users\\samson\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy>=2.0.0a18->en-core-web-sm==2.0.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Running setup.py bdist_wheel for en-core-web-sm: started\n",
      "  Running setup.py bdist_wheel for en-core-web-sm: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Samson\\AppData\\Local\\pip\\Cache\\wheels\\54\\7c\\d8\\f86364af8fbba7258e14adae115f18dd2c91552406edc3fdaa\n",
      "Successfully built en-core-web-sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse a single quote.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected unicode, got str)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-53df0722ca8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#ERROR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"this is a very nice sentence about football and food\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msentence_parsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Samson\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\spacy\\language.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable)\u001b[0m\n\u001b[0;32m    344\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[0;32m    345\u001b[0m                                                 max_length=self.max_length))\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Samson\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\spacy\\language.pyc\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected unicode, got str)"
     ]
    }
   ],
   "source": [
    "#ERROR\n",
    "sentence = \"this is a very nice sentence about football and food\"\n",
    "sentence_parsed = en_nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = u\"this is a very nice sentence about football and food\"\n",
    "sentence_parsed = en_nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_parsed) # number of words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_parsed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence_parsed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_parsed.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(this, u'DET')\n",
      "(is, u'VERB')\n",
      "(a, u'DET')\n",
      "(very, u'ADV')\n",
      "(nice, u'ADJ')\n",
      "(sentence, u'NOUN')\n",
      "(about, u'ADP')\n",
      "(football, u'NOUN')\n",
      "(and, u'CCONJ')\n",
      "(food, u'NOUN')\n"
     ]
    }
   ],
   "source": [
    "for token in sentence_parsed:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'ADJ': 1,\n",
       " u'ADP': 1,\n",
       " u'ADV': 1,\n",
       " u'CCONJ': 1,\n",
       " u'DET': 2,\n",
       " u'NOUN': 3,\n",
       " u'VERB': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counts = {}\n",
    "for token in sentence_parsed:\n",
    "    pos = token.pos_\n",
    "    pos_counts[pos] = pos_counts.get(pos,0) + 1\n",
    "    \n",
    "pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'ADJ': 0.1,\n",
       " u'ADP': 0.1,\n",
       " u'ADV': 0.1,\n",
       " u'CCONJ': 0.1,\n",
       " u'DET': 0.2,\n",
       " u'NOUN': 0.3,\n",
       " u'VERB': 0.1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_perc = {}\n",
    "for k,v in pos_counts.items():\n",
    "    pos_perc [k] = 1.*v/len(sentence_parsed)\n",
    "    \n",
    "pos_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Those are new features you can use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "#  \n",
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48994</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>deciduous_holly</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50056</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>deuteromycotina</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83067</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>lebanon</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47648</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>cuss</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87635</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>march_17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10965</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>made-to-order</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98062</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>oscar_fingal_o'flahertie_wills_wilde</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>togolese</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12284</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>nonelective</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>brown-striped</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pos                                  word  pos_score  neg_score\n",
       "48994  NOUN                       deciduous_holly      0.000      0.000\n",
       "50056  NOUN                       deuteromycotina      0.000      0.000\n",
       "83067  NOUN                               lebanon      0.000      0.000\n",
       "47648  NOUN                                  cuss      0.000      0.125\n",
       "87635  NOUN                              march_17      0.000      0.000\n",
       "10965   ADJ                         made-to-order      0.000      0.000\n",
       "98062  NOUN  oscar_fingal_o'flahertie_wills_wilde      0.000      0.000\n",
       "18362   ADJ                              togolese      0.000      0.000\n",
       "12284   ADJ                           nonelective      0.000      0.500\n",
       "3051    ADJ                         brown-striped      0.125      0.000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sen = pd.read_csv('datasets/sentiment_words_simple.csv')\n",
    "sen['pos'] = sen['pos'].str.upper()\n",
    "\n",
    "sen.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define positive-negative\n",
    "sen['pos_vs_neg'] = sen['pos_score'] - sen['neg_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos_vs_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116721</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pos      word  pos_score  neg_score  pos_vs_neg\n",
       "116721  NOUN  sentence        0.0        0.0         0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 1\n",
    "sen[(sen['word']=='sentence') & (sen['pos']=='NOUN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can get a score for each word and average the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(very, u'ADV', 0.125)\n",
      "(nice, u'ADJ', 0.5750000000000001)\n",
      "(sentence, u'NOUN', 0.0)\n",
      "(football, u'NOUN', 0.0)\n",
      "(food, u'NOUN', -0.0416666666667)\n"
     ]
    }
   ],
   "source": [
    "for token in sentence_parsed:\n",
    "    score = sen[(sen['word']==str(token)) & (sen['pos'].astype(unicode)==str(token.pos_))]['pos_vs_neg'].values\n",
    "    if len(score)>0:\n",
    "        print(token, token.pos_,score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most-obj'></a>\n",
    "#  \n",
    "#  \n",
    "#  \n",
    "## Objective and Subjective\n",
    "---\n",
    "\n",
    "Objective = 1 - (positive+negative)  \n",
    "\n",
    "\"terrible\":\n",
    "    * positve = 0.0\n",
    "    * negative = 0.8\n",
    "    * objective = 0.2\n",
    "    \n",
    "\"very\":\n",
    "    * positve = 0.7\n",
    "    * negative = 0.0\n",
    "    * objective = 0.3\n",
    "    \n",
    "\"room\":\n",
    "    * positve = 0.02\n",
    "    * negative = 0.03\n",
    "    * objective = 0.95\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "#  \n",
    "\n",
    "## Sentiment Scores with VADER Library\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score is computed based on individual words. not robust as RNN. for simple baseline model use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install vaderSentiment.\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['Hawthorne is by turn outrageous and pathetic and imperious and poignant and very funny.',\n",
    "            'Delivers guilt-free escapism about pretty people having wicked-hot fun in pretty places.',\n",
    "            'Brian De Palma take on Tom Wolfe The Bonfire of the Vanities is a misfire of inanities.',\n",
    "            'I hated this movie. Hated hated hated hated hated this movie. Hated it.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawthorne is by turn outrageous and pathetic and imperious and poignant and very funny.\n",
      "{'neg': 0.321, 'neu': 0.526, 'pos': 0.153, 'compound': -0.5434}\n",
      "\n",
      "Delivers guilt-free escapism about pretty people having wicked-hot fun in pretty places.\n",
      "{'neg': 0.0, 'neu': 0.481, 'pos': 0.519, 'compound': 0.8658}\n",
      "\n",
      "Brian De Palma take on Tom Wolfe The Bonfire of the Vanities is a misfire of inanities.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "I hated this movie. Hated hated hated hated hated this movie. Hated it.\n",
      "{'neg': 0.855, 'neu': 0.145, 'pos': 0.0, 'compound': -0.9854}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print sentence\n",
    "    print vs\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
