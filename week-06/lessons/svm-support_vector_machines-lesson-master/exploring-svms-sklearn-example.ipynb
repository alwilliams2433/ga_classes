{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Codealong Exploring SVMs Using Sklearn\n",
    "\n",
    "_Authors: Joseph Nelson (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, linear_model, datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the handwritten digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()\n",
    "y = data.target\n",
    "X = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797L,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797L, 64L)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      "  15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "   0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "   0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print y[:10]\n",
    "print X[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.101836\n",
       "5    0.101280\n",
       "1    0.101280\n",
       "6    0.100723\n",
       "4    0.100723\n",
       "9    0.100167\n",
       "7    0.099610\n",
       "0    0.099054\n",
       "2    0.098497\n",
       "8    0.096828\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_pd = pd.DataFrame(y)\n",
    "y_pd[0].value_counts()/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cross-validate a logistic regression on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90810811 0.95081967 0.89502762 0.91111111 0.94972067 0.96648045\n",
      " 0.97765363 0.9494382  0.85875706 0.94318182]\n",
      "0.9310298346839012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#sklearn with CV test score\n",
    "logreg = LogisticRegression()\n",
    "accs = cross_val_score(logreg, X, y, cv=10)\n",
    "print accs\n",
    "print np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cross-validate a SVM on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas, 'kernel':['linear','rbf']}\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, cv=5, scoring='f1_weighted')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882154882154882"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm = grid_search.best_estimator_\n",
    "best_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def print_cm_cr(y_true, y_pred):\n",
    "    \"\"\"prints the confusion matrix and the classification report\"\"\"\n",
    "    confusion = pd.crosstab(y_true, \n",
    "                            y_pred, \n",
    "                            rownames=['Actual'], \n",
    "                            colnames=['Predicted'], \n",
    "                            margins=True)\n",
    "    print confusion\n",
    "    print\n",
    "    print classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
      "Actual                                                \n",
      "0          55   0   0   0   0   0   0   0   0   0   55\n",
      "1           0  55   0   0   0   0   0   0   0   0   55\n",
      "2           0   0  67   0   0   0   0   0   0   0   67\n",
      "3           0   0   0  63   0   0   0   1   0   0   64\n",
      "4           0   0   0   0  52   0   0   0   0   2   54\n",
      "5           0   0   0   0   0  52   0   0   0   1   53\n",
      "6           0   0   0   0   0   1  69   0   0   0   70\n",
      "7           0   0   0   0   0   0   0  53   0   0   53\n",
      "8           0   2   0   0   0   0   0   0  60   0   62\n",
      "9           0   0   0   0   0   0   0   0   0  61   61\n",
      "All        55  57  67  63  52  53  69  54  60  64  594\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        55\n",
      "          1       0.96      1.00      0.98        55\n",
      "          2       1.00      1.00      1.00        67\n",
      "          3       1.00      0.98      0.99        64\n",
      "          4       1.00      0.96      0.98        54\n",
      "          5       0.98      0.98      0.98        53\n",
      "          6       1.00      0.99      0.99        70\n",
      "          7       0.98      1.00      0.99        53\n",
      "          8       1.00      0.97      0.98        62\n",
      "          9       0.95      1.00      0.98        61\n",
      "\n",
      "avg / total       0.99      0.99      0.99       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_svm.fit(X_train, y_train).predict(X_test)\n",
    "print_cm_cr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97802198 0.95027624 0.98328691 0.98879552 0.96338028]\n",
      "0.9727521858182637\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(kernel='rbf',C=10, gamma=0.001)\n",
    "accs = cross_val_score(SVM, X, y, cv=5)\n",
    "print accs\n",
    "print np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(X_train, y_train).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian SVM has two parameters, gamma and C\n",
    "\n",
    "---\n",
    "\n",
    "### gamma\n",
    "\n",
    "Intuitively, the gamma parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. \n",
    "\n",
    "The higher the value of gamma, the more it will try to exactly fit the training data set. Will cause over-fitting problem.\n",
    "- small gamma: the model is constrained, can under-fit!  high bias and low variance.\n",
    "- big gamma: Tries to capture the shape too well: can over-fit!  low bias and high variance.\n",
    "\n",
    "<img src=\"http://www.analyticsvidhya.com/wp-content/uploads/2015/10/SVM_15.png\">\n",
    "\n",
    "\n",
    "\n",
    "### C\n",
    "\n",
    "Penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly. C can be thought of as the parameter for the soft margin cost function, which controls the influence of each individual support vector\n",
    "\n",
    "- small C: makes the decision surface smooth and simple, softer margin can under-fit! high bias and low variance.\n",
    "- big C: selects more support vectors: can over-fit! harder margin. low bias and high variance.\n",
    "\n",
    "<img src=\"http://www.analyticsvidhya.com/wp-content/uploads/2015/10/SVM_18.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit an SVM modifying the default gamma and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gridsearch an optimal gamma with C=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Gridsearch the optimal C, gamma, and kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7. Import the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150L,)\n",
      "(150L, 4L)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "y = iris.target\n",
    "X = iris.data\n",
    "print y.shape\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Cross-validate a default logistic regression and default SVM on the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         0.93333333 0.93333333 0.93333333\n",
      " 0.8        0.93333333 1.         1.        ]\n",
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#sklearn with CV test score\n",
    "logreg = LogisticRegression()\n",
    "accs = cross_val_score(logreg, X, y, cv=10)\n",
    "print accs\n",
    "print np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "SVM1 = svm.SVC(kernel='rbf')\n",
    "accs = cross_val_score(SVM1, X, y, cv=5)\n",
    "print accs\n",
    "print np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm, grid_search\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "SVM2 = svm.SVC(kernel='rbf',C=1, gamma=0.1)\n",
    "accs = cross_val_score(SVM2, X, y, cv=5)\n",
    "print accs\n",
    "print np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. [Bonus] Compare three SVMs with different kernels on the iris data visually.\n",
    "- Gaussian\n",
    "- Linear\n",
    "- Poly of degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "SVM1 = svm.SVC(kernel='linear')\n",
    "accs = cross_val_score(SVM1, X, y, cv=5)\n",
    "print accs\n",
    "print np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.9        0.93333333 1.        ]\n",
      "0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "SVM1 = svm.SVC(kernel='poly', degree=3)\n",
    "accs = cross_val_score(SVM1, X, y, cv=5)\n",
    "print accs\n",
    "print np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. [Bonus] Compare SVM kernels visually on fake data using sklearn's `make_circles`.\n",
    "\n",
    "Load `make_circles` from here:\n",
    "```python\n",
    "from sklearn.datasets import make_circles\n",
    "```\n",
    "\n",
    "Compare the linear, rbf, and poly kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
