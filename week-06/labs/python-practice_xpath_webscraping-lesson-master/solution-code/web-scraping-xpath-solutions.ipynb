{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practicing Web Scraping With XPath\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Build a basic scraper\n",
    "- Understand HTML and XPath basics\n",
    "- Scrape a website for various data and putting your results into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Review of HTML and Web Scraping](#review1)\n",
    "- [Review of XPath](#review2)\n",
    "- [Basic XPath Expressions](#basic-xpath)\n",
    "    - [Absolute References](#absolute)\n",
    "    - [Relative References](#relative-references)\n",
    "    - [Selecting Attributes](#attributes)\n",
    "- [Guided Practice: Where's Waldo? - XPath Edition](#practice1)\n",
    "- [1 vs. N Selections](#1vsn)\n",
    "    - [Selecting the First Element in a Series of Elements](#first-elem)\n",
    "    - [Selecting the Last Element in a Series of Elements](#last-elem)\n",
    "    - [Selecting all Elements Matching a Selection](#all-elem-match)\n",
    "    - [Selecting Elements Matching an Attribute](#elem-match-attr)\n",
    "- [Guided Practice: Selecting Elements](#practice2)\n",
    "- [A Quick Note: The Requests Module](#requests)\n",
    "- [Guided Practice: Scrape DataTau Headlines](#practice3)\n",
    "- [Independent Practice](#independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review1'></a>\n",
    "## Review of HTML and Web Scraping\n",
    "\n",
    "---\n",
    "\n",
    "Web scraping is a technique of extracting information from websites. It's the downloading and transformation of unstructured web data into structured data that can be stored and analyzed.\n",
    "\n",
    "There are a variety of ways to \"scrape\" what we want from the web:\n",
    "- Using third-party services (import.io).\n",
    "- By writing our own Python apps that pull HTML documents and parse them.\n",
    "  - Mechanize\n",
    "  - Scrapy\n",
    "  - Requests\n",
    "  - Libxml/XPath\n",
    "  - Regular expressions\n",
    "  - BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Check:** What do you perceive to be the hardest aspect of scraping?\n",
    "\n",
    "_E.G.: If you were asked to scrape Craigslist property listings and put them in a DataFrame, what would hold you up?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: HTML\n",
    "\n",
    "In the HTML document object model (DOM), everything is a node:\n",
    " * The document itself is a document node\n",
    " * All HTML elements are element nodes\n",
    " * All HTML attributes are attribute nodes\n",
    " * The text inside HTML elements are text nodes\n",
    " * The comments are comment nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Elements\n",
    "Elements begin and end with **opening and closing tags** that are defined by namespaced, encapsulated strings. \n",
    "\n",
    "```html\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "_Note: The tags **title, p,** and **strong** are represented below._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Element Parent/Child Relationships\n",
    "\n",
    "<img src=\"http://www.htmlgoodies.com/img/2007/06/flowChart2.gif\" width=\"250\">\n",
    "\n",
    "**Elements begin and end in the same namespace, like so:** `<p></p>`\n",
    "\n",
    "**Elements can have parents and children.** It's important to remember that an element can be both a parent and a child, and whether to refer to the element as a parent or a child depends on the specific element you are referencing.\n",
    "\n",
    "_Your parents are **parents** to you but **children** of your grandparents. The same logic applies with HTML elements._\n",
    "\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the child of 'parent.'\n",
    "        <div id = 'child_2'>I am the child of 'child_1.'\n",
    "            <div id = 'child_3'>I am the child of 'child_2.'\n",
    "                <div id = 'child_4'>I am the child of 'child_4.'</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```\n",
    "\n",
    "**or**\n",
    "\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the parent of 'child_2.'\n",
    "        <div id = 'child_2'>I am the parent of 'child_3.'\n",
    "            <div id = 'child_3'> I am the parent of 'child_4.'\n",
    "                <div id = 'child_4'>I am not a parent. </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Element Attributes\n",
    "\n",
    "Elements can also have attributes. Attributes are defined inside **element tags** and can contain data that may be useful to scrape.\n",
    "\n",
    "```html\n",
    "<a href=\"http://lmgtfy.com/?q=html+element+attributes\" title=\"A title\" id=\"web-link\" name=\"hal\">A Simple Link</a>\n",
    "```\n",
    "\n",
    "The **element attributes** of this `<a>` tag element are:\n",
    "- `id`\n",
    "- `href`\n",
    "- `title`\n",
    "- `name`\n",
    "\n",
    "This `<a>` tag example will render in your browser like this:\n",
    "> <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">A Simple Link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Can you identify an attribute, an element, a text item, and a child element in the code below?\n",
    "\n",
    "```HTML\n",
    "<html>\n",
    "   <title id=\"main-title\">All this scraping is making me itch!</title>\n",
    "   <body>\n",
    "       <h1>Welcome to my Homepage</h1>\n",
    "       <p id=\"welcome-paragraph\" class=\"strong-paragraph\">\n",
    "           <span>Hello friends, let me tell you about this cool hair product.</span>\n",
    "           <ul>\n",
    "              <li>It's cool.</li>\n",
    "              <li>It's fresh.</li>\n",
    "              <li>It can tell the future.</li>\n",
    "              <li>Always be closing.</li>\n",
    "           </ul>\n",
    "       </p>\n",
    "   </body>\n",
    "```\n",
    "\n",
    "**Bonus:** What's missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review2'></a>\n",
    "## Review of XPath\n",
    "\n",
    "---\n",
    "\n",
    "XPath uses path expressions to select nodes or node sets in an HTML/XML document. These path expressions look similar to the expressions you see when you work with a traditional computer file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath Features\n",
    "\n",
    "XPath includes more than 100 built-in functions to help us select and manipulate HTML (or XML) documents. XPath has functions for:\n",
    "\n",
    "- String values\n",
    "- Numeric values\n",
    "- Date and time comparison\n",
    "- Sequence manipulation\n",
    "- Boolean values\n",
    "- And more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic-xpath'></a>\n",
    "## Basic XPath Expressions\n",
    "\n",
    "---\n",
    "\n",
    "XPath comes with a wide array of features, but the basics of selecting data are the most common problems that XPath can help you solve.\n",
    "\n",
    "Most often, you'll use **XPath** for selecting data from HTML documents. There are two ways you can **select elements** within HTML using **XPath**:\n",
    "\n",
    "- Absolute references\n",
    "- Relative references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='absolute'></a>\n",
    "### Absolute References\n",
    "\n",
    "> _For our XPath demonstration, we'll use Scrapy, which is using [Libxml](http://xmlsoft.org) under the hood. Libxml provides the basic functionality for XPath expressions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pip install Scrapy.\n",
    "# Pip install --upgrade zope2.\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <span id=\"only-span\">good</span>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# The same thing, but an absolute reference:\n",
    "Selector(text=HTML).xpath('/html/body/span/text()').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='relative-references'></a>\n",
    "### Relative References\n",
    "\n",
    "Relative references in XPath match the \"ends\" of structures. As there is only a single `span` element, `//span/text()` matches **one element**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "### Selecting Attributes\n",
    "\n",
    "Attributes are **within a tag**, such as `id=\"only-span\"` within our `span` attribute. We can get the attribute by using the `@` symbol **after** the **element reference**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'only-span']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/@id').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice1'></a>\n",
    "## Guided Practice: Where's Waldo? — XPath Edition\n",
    "\n",
    "---\n",
    "\n",
    "**In this example, we'll find Waldo together. Find Waldo as:**\n",
    "\n",
    "- An element\n",
    "- An attribute\n",
    "- A text element\n",
    "\n",
    "The practice HTML string is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        \n",
    "        <ul id=\"waldo\">\n",
    "            <li class=\"waldo\">\n",
    "                <span> yo I'm not here</span>\n",
    "            </li>\n",
    "            <li class=\"waldo\">Height:  ???</li>\n",
    "            <li class=\"waldo\">Weight:  ???</li>\n",
    "            <li class=\"waldo\">Last Location:  ???</li>\n",
    "            <li class=\"nerds\">\n",
    "                <div class=\"alpha\">Bill Gates</div>\n",
    "                <div class=\"alpha\">Zuckerberg</div>\n",
    "                <div class=\"beta\">Theil</div>\n",
    "                <div class=\"animal\">Parker</div>\n",
    "            </li>\n",
    "        </ul>\n",
    "        \n",
    "        <ul id=\"tim\">\n",
    "            <li class=\"tdawg\">\n",
    "                <span>yo im here</span>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <li>stuff</li>\n",
    "        <li>stuff2</li>\n",
    "        \n",
    "        <div id=\"cooldiv\">\n",
    "            <span class=\"dsi-rocks\">\n",
    "               YO!\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <waldo>Waldo</waldo>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'nerds',\n",
       " u'alpha',\n",
       " u'alpha',\n",
       " u'beta',\n",
       " u'animal',\n",
       " u'tdawg',\n",
       " u'dsi-rocks']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//@class').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Waldo']\n",
      "[u'\\n                ', u'\\n            ', u'Height:  ???', u'Weight:  ???', u'Last Location:  ???', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n            ', u'\\n                ', u'\\n            ']\n",
      "[u'<li class=\"waldo\">\\n                <span> yo I\\'m not here</span>\\n            </li>', u'<li class=\"waldo\">Height:  ???</li>', u'<li class=\"waldo\">Weight:  ???</li>', u'<li class=\"waldo\">Last Location:  ???</li>', u'<li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>', u'<li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>', u'<li>stuff</li>', u'<li>stuff2</li>']\n",
      "[u'waldo', u'waldo', u'waldo', u'waldo', u'nerds', u'alpha', u'alpha', u'beta', u'animal', u'tdawg', u'dsi-rocks']\n",
      "[u'waldo', u'tim']\n"
     ]
    }
   ],
   "source": [
    "# Find the absolute element.\n",
    "print Selector(text=HTML).xpath('/html/body/waldo/text()').extract()\n",
    "print Selector(text=HTML).xpath('/html/body/ul/li/text()').extract()\n",
    "\n",
    "# Find the relative element.\n",
    "print Selector(text=HTML).xpath('//li').extract()\n",
    "\n",
    "# Find the element attribute.\n",
    "print Selector(text=HTML).xpath('////@class').extract()\n",
    "print Selector(text=HTML).xpath('//ul/@id').extract()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'waldo', u'waldo', u'waldo', u'waldo', u'nerds', u'alpha', u'alpha', u'beta', u'animal', u'tdawg', u'dsi-rocks']\n"
     ]
    }
   ],
   "source": [
    "print Selector(text=HTML).xpath('//@class').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'waldo', u'waldo', u'waldo', u'waldo', u'nerds', u'alpha', u'alpha', u'beta', u'animal', u'tdawg', u'dsi-rocks']\n"
     ]
    }
   ],
   "source": [
    "print Selector(text=HTML).xpath('//*/@class').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1vsn'></a>\n",
    "## 1 vs N Selections\n",
    "\n",
    "---\n",
    "\n",
    "When selecting elements via relative reference, it's possible that you'll select multiple items. It's still possible to select single items if you're specific enough.\n",
    "\n",
    "**Singular Reference**\n",
    "- **Index** starts at **1**\n",
    "- Selections by offset\n",
    "- Selections by \"first\" or \"last\"\n",
    "- Selections by **unique attribute value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "    \n",
    "        <!-- Search Results -->\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=751hUX_q0Do\" title=\"Rappin with Gas\">Rapping with gas</a>\n",
    "           <span class=\"link-details\">This is a great video about gas.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=97byWqi-zsI\" title=\"Casio Rapmap\">The Rapmaster</a>\n",
    "           <span class=\"link-details\">My first synth ever.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=TSwqnR327fk\" title=\"Cinco Products\">Cinco Midi Organizer</a>\n",
    "           <span class=\"link-details\">Midi files at the speed of light.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">BBG Baddest Moments</a>\n",
    "           <span class=\"link-details\">It's tough to be a gangster.</span>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Page stats -->\n",
    "        <div class=\"page-stats-container\">\n",
    "            <li class=\"item\" id=\"pageviews\">1,333,443</li>\n",
    "            <li class=\"item\" id=\"somethingelse\">bla</li>\n",
    "            <li class=\"item\" id=\"last-viewed\">01-22-2016</li>\n",
    "            <li class=\"item\" id=\"views-per-hour\">1,532</li>\n",
    "            <li class=\"item\" id=\"kiefer-views-per-hour\">5,233.42</li>\n",
    "        </div>\n",
    "        \n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "span = Selector(text=HTML).xpath('/html/body/div/li[@id=\"kiefer-views-per-hour\"]/text()').extract()\n",
    "span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first-elem'></a>\n",
    "### Selecting the First Element in a Series of Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">This is a great video about gas.</span>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='last-elem'></a>\n",
    "### Selecting the Last Element in a Series of Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='all-elem-match'></a>\n",
    "### Selecting All Elements Matching a Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<span class=\"link-details\">This is a great video about gas.</span>',\n",
       " u'<span class=\"link-details\">My first synth ever.</span>',\n",
       " u'<span class=\"link-details\">Midi files at the speed of light.</span>',\n",
       " u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elem-match-attr'></a>\n",
    "### Selecting Elements Matching An _Attribute_\n",
    "\n",
    "This will be one of the most common ways you'll select items. HTML DOM elements will be more differentiated based on their class and ID variables. Mainly, these types of attributes are used by web developers to refer to specific elements or a broad set of elements to apply visual characteristics to using CSS.\n",
    "\n",
    "```HTML \n",
    "//element[@attribute=\"value\"]\n",
    "```\n",
    "\n",
    "**Generally:**\n",
    "\n",
    "- \"Class\" attributes within elements usually refer to multiple items\n",
    "- \"ID\" attributes are supposed to be unique but aren't always\n",
    "\n",
    "_CSS stands for cascading style sheets. These are used to abstract the definition of visual elements on a micro and macro scale for the web. They are also our best friend as data miners. They give us strong hints and cues as to how a web document is structured._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice2'></a>\n",
    "## Guided Practice: Selecting Elements\n",
    "\n",
    "---\n",
    "\n",
    "1) How can we get a series of only text items for the page statistics section of our page?<br>\n",
    "2) We want to know only how many times Kiefer views the YouTube videos page per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//li/text()' data=u'1,333,443'>,\n",
       " <Selector xpath='//li/text()' data=u'bla'>,\n",
       " <Selector xpath='//li/text()' data=u'01-22-2016'>,\n",
       " <Selector xpath='//li/text()' data=u'1,532'>,\n",
       " <Selector xpath='//li/text()' data=u'5,233.42'>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all text elements for the page statistics section.\n",
    "Selector(text=HTML).xpath('//li/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1,532']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the text for \"Kiefer's\" number of views per hour.\n",
    "Selector(text=HTML).xpath('//div[@class=\"page-stats-container\"]/li[4]/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the text for \"Kiefer's\" number of views per hour.\n",
    "Selector(text=HTML).xpath('//li[@id=\"kiefer-views-per-hour\"]/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "## A Quick Note on the Requests Module\n",
    "\n",
    "---\n",
    "\n",
    "The requests module is the gateway to interacting with the web using Python. We can:\n",
    "\n",
    " - Fetch web documents as strings\n",
    " - Decode JSON\n",
    " - Complete basic data munging with web documents\n",
    " - Download static files that aren't text, including:\n",
    "  - Images\n",
    "  - Videos\n",
    "  - Binary data\n",
    "\n",
    "\n",
    "Take some time and read up on requests:\n",
    "\n",
    "http://docs.python-requests.org/en/master/user/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice3'></a>\n",
    "## Guided Practice: Scrape DataTau Headlines\n",
    "\n",
    "DataTau is a great site for data science news. Let's take its headlines using Python **`requests`** and practice selecting various elements.\n",
    "\n",
    "Using the <a href=\"https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en\">XPath Helper Chrome plugin</a> _(cmd-shift-x)_ and the Chrome Inspect feature, let's explore the structure of the page.\n",
    "\n",
    "_Here's a <a href=\"https://www.youtube.com/watch?v=i2Li1vnv09U\">concise video</a> that demonstrates the basic Inspect feature in Chrome._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<html><head><link rel=\"stylesheet\" type=\"text/css\" href=\"news.css\">\\n<link rel=\"shortcut icon\" href=\"http://www.iconj.com/ico/d/x/dxo02ap56v.ico\">\\n<scr'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please only run this frame once to avoid hitting the site too hard all at once.\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://www.datatau.com\")\n",
    "HTML = response.text  \n",
    "HTML[0:150]           # View the first 500 characters of the HTML index document for DataTau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Only the Headlines\n",
    "\n",
    "We'll use the XPath Helper tool to inspect the markup that comprises the **title** to find a pattern. Because there is more than one **title**, we expect to find a series of elements representing the **title** data we're interested in.\n",
    "\n",
    "In this example, we are referencing the **first center**, **third table row (`tr[3]`)** within the second **td having a class of \"title\" (`td[@class=\"title\"][2]`)** and the anchor tag within a **(`a/text()`)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1.1 Billion Taxi Rides with SQLite, Parquet & HDFS',\n",
       " u'Introducing the IRONdb Prometheus Adapter',\n",
       " u'Spatiotemporal modeling with R',\n",
       " u'Python libraries and packages for Data Scientists (the 5 most important ones)',\n",
       " u'Scaling Pandas to the Billions with Ibis and MapD',\n",
       " u'Introducing plotly.py 3.0.0',\n",
       " u'Tutorial: Setting up an IPFS peer, part IV',\n",
       " u'Announcing MapD 4.0: Geospatial, Role-Based Permissions and Updates/Deletes',\n",
       " u'The Good, Bad and Ugly: Apache Spark for Data Science Work',\n",
       " u'How to balance the load on a data team']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/text()').extract()\n",
    "titles[0:10] # The first five titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Can We Get the URLs From the Titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=YiLBH4Io00',\n",
       " u'https://statsbot.co/blog/business-metrics-for-startups/',\n",
       " u'https://statsbot.co/blog/bigquery-vs-redshift-pricing/',\n",
       " u'https://blog.alookanalytics.com/2018/06/11/geolocated-nearest-neighbors-in-product-campaign-targeting/',\n",
       " u'https://www.medium.com/activewizards-machine-learning-company/top-20-r-libraries-for-data-science-in-2018-infographic-956f8419f883/',\n",
       " u'https://www.medium.com/activewizards-machine-learning-company/top-7-data-science-use-cases-in-finance-303c05a3cb58/',\n",
       " u'https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8',\n",
       " u'https://medium.com/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05',\n",
       " u'https://www.medium.com/data-science-school/practical-apache-spark-in-10-minutes-part-2-rdd-8e34c7663d6d/',\n",
       " u'http://www.sharpsightlabs.com/blog/key-for-mastering-data-science/',\n",
       " u'https://medium.com/nanonets/how-we-flew-a-drone-to-monitor-construction-projects-in-africa-using-deep-learning-b792f5c9c471',\n",
       " u'http://datasciencedigest.flyelephant.net/issues/datascience-digest-issue-13-88803',\n",
       " u'https://medium.com/textileio/decentralized-code-distribution-for-the-future-of-open-source-2dc58f1153b2',\n",
       " u'https://github.com/nateraw/Lda2vec-Tensorflow',\n",
       " u'http://outlace.com/TensorNets1.html',\n",
       " u'https://www.interviewqs.com/',\n",
       " u'https://courses.data36.com/p/the-junior-data-scientist-s-first-month-online-video-course',\n",
       " u'https://medium.com/acing-ai/walmart-data-science-interview-questions-acing-the-ai-interview-a775b264b015',\n",
       " u'https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219',\n",
       " u'http://www.theanalyticslab.nl/2018/06/24/telegram-messages/',\n",
       " u'https://medium.com/acing-ai/artificial-intelligence-is-the-bicycle-for-our-technology-my-udacity-ama-a7068afc6ed9',\n",
       " u'https://statsbot.co/blog/data-team',\n",
       " u'https://thenewstack.io/the-good-bad-and-ugly-apache-spark-for-data-science-work/',\n",
       " u'https://www.mapd.com/blog/announcing-mapd-4.0/',\n",
       " u'https://medium.com/textileio/tutorial-setting-up-an-ipfs-peer-part-iv-1595d4ba221b',\n",
       " u'https://medium.com/@plotlygraphs/introducing-plotly-3-0-0-7bb1333f69c6',\n",
       " u'https://www.mapd.com/blog/scaling-pandas-to-the-billions-with-ibis-and-mapd',\n",
       " u'https://data36.com/python-libraries-packages-data-scientists/',\n",
       " u'https://github.com/Italosayan/P-P-P',\n",
       " u'https://www.circonus.com/2018/06/prometheus-adapter/',\n",
       " u'http://tech.marksblogg.com/billion-nyc-taxi-rides-sqlite-parquet-hdfs.html']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/@href').extract()\n",
    "urls[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1.1 Billion Taxi Rides with SQLite, Parquet & HDFS',\n",
       " u'Introducing the IRONdb Prometheus Adapter',\n",
       " u'Spatiotemporal modeling with R',\n",
       " u'Python libraries and packages for Data Scientists (the 5 most important ones)',\n",
       " u'Scaling Pandas to the Billions with Ibis and MapD']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[0:5] # The first five titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Can We Get the Site Domain After the Title Within the Parentheses (i.e., stitchfix.com)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = Selector(text=HTML).xpath(\"//span[@class='comhead']/text()\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' (marksblogg.com) ',\n",
       " u' (circonus.com) ',\n",
       " u' (github.com) ',\n",
       " u' (data36.com) ',\n",
       " u' (mapd.com) ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How About the Points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2 points', u'2 points', u'3 points', u'5 points', u'2 points']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = Selector(text=HTML).xpath('//td[@class=\"subtext\"]/span/text()').extract()\n",
    "points[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How About the \"More\" Link?\n",
    "\n",
    "> *Hint: You can use `element[text()='exact text']` to find text elements matching specific text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=YiLBH4Io00']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_link = Selector(text=HTML).xpath('//a[text()=\"More\"]/@href').extract()\n",
    "next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='independent'></a>\n",
    "## Independent Practice\n",
    "\n",
    "---\n",
    "\n",
    "**For the next 30 minutes, try to grab the following from DataTau:**\n",
    "\n",
    "- Story titles\n",
    "- Story URL (href)\n",
    "- Domain\n",
    "- Points\n",
    "\n",
    "**Stretch goals:**\n",
    "- Author\n",
    "- Comment count\n",
    "\n",
    "**Put your results into a DataFrame.**\n",
    "\n",
    "- Perform a basic analysis of domains and point distributions\n",
    "\n",
    "**Bonus**\n",
    "\n",
    "Automatically find the next \"more\" link and mine the next page(s) until none exist. Logically, you can parse each page with this pseudocode:\n",
    "\n",
    "- Does the next link exist (a tag with `text == \"More\"`)?\n",
    "- Fetch the URL, prepended with domain (`datatau.com/(extracted link here)`)\n",
    "- Parse the page with `Selector(text=HTML).xpath('').extract()` to find the elements\n",
    "- Add to DataFrame\n",
    "\n",
    "> _Note: You might want to set a limit — something like 2–3 total requests per attempt — to avoid unnecessary transfer._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://www.datatau.com\"\n",
    "response  =  requests.get(url)\n",
    "links     =  Selector(text=response.text).xpath(\"//td[@class='title']/a/@href\").extract()\n",
    "titles    =  Selector(text=response.text).xpath(\"//td[@class='title']/a/text()\").extract()\n",
    "points    =  Selector(text=response.text).xpath(\"//td[@class='subtext']/span/text()\").extract()\n",
    "domains   =  Selector(text=response.text).xpath(\"//td[@class='title']/span/text()\").extract()\n",
    "authors   =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'user')]/text()\").extract()\n",
    "comments  =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'item')]/text()\").extract()\n",
    "\n",
    "expected_length = 30\n",
    "\n",
    "# Add [np.nan]*(expected_length - len(points)) to the end of the lists. It will fill in missing\n",
    "# values that sometimes don't exist at the end of the results.\n",
    "# scraped = dict(\n",
    "#     titles   =  titles[:30], \n",
    "#     links    =  links[:30], # :30 because of that \"more\" link.\n",
    "#     points   =  points + [np.nan]*(expected_length - len(points)),\n",
    "#     domains  =  domains + [np.nan]*(expected_length - len(domains)),\n",
    "#     authors  =  authors + [np.nan]*(expected_length - len(authors)),\n",
    "#     comments =  comments + [np.nan]*(expected_length - len(comments))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1.1 Billion Taxi Rides with SQLite, Parquet & HDFS',\n",
       " u'Introducing the IRONdb Prometheus Adapter',\n",
       " u'Spatiotemporal modeling with R',\n",
       " u'Python libraries and packages for Data Scientists (the 5 most important ones)',\n",
       " u'Scaling Pandas to the Billions with Ibis and MapD',\n",
       " u'Introducing plotly.py 3.0.0',\n",
       " u'Tutorial: Setting up an IPFS peer, part IV',\n",
       " u'Announcing MapD 4.0: Geospatial, Role-Based Permissions and Updates/Deletes',\n",
       " u'The Good, Bad and Ugly: Apache Spark for Data Science Work',\n",
       " u'How to balance the load on a data team',\n",
       " u'Artificial Intelligence is the Bicycle for our Technology',\n",
       " u'Let R/Python send messages when the algorithms are done training',\n",
       " u'Automated Feature Engineering in Python',\n",
       " u'Walmart Data Science Interview Questions',\n",
       " u\"The Junior Data Scientist's First Month (Class of July, 2018)\",\n",
       " u'Practice DS interview questions through email newsletter',\n",
       " u'Tensor Networks and the Nature of Non-Linearity',\n",
       " u'Simple topic modeling using tensorflow',\n",
       " u'Decentralized code distribution for the future of open source',\n",
       " u'DataScience Digest - Issue #13',\n",
       " u'How to easily automate Drone-based monitoring using Deep Learning',\n",
       " u'A key for mastering data science',\n",
       " u'Practical Apache Spark in 10 minutes. Part 2',\n",
       " u'How to easily do Topic Modeling with LSA, PSLA, LDA & lda2Vec',\n",
       " u'Reinforcement Learning from scratch',\n",
       " u'Top 7 Data Science Use Cases in Finance',\n",
       " u'Top 20 R Libraries for Data Science in 2018 [Infographic]',\n",
       " u'Geolocated nearest neighbors in product campaign targeting',\n",
       " u'SQL queries to optimize BigQuery costs',\n",
       " u'The Complex Analytical Process to Define Business Metrics',\n",
       " u'More']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31, 30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles),len(links),len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching http://www.datatau.com/x?fnid=YiLBH4Io00...\n",
      "Fetching http://www.datatau.com/x?fnid=nhTvrNPb7g...\n",
      "Fetching http://www.datatau.com/x?fnid=8GVqusgTXE...\n",
      "Fetching http://www.datatau.com/x?fnid=Rv8q55z9eU...\n",
      "Fetching http://www.datatau.com/x?fnid=PTf8VsqpWK...\n",
      "Fetching http://www.datatau.com/x?fnid=X9M3CMxuk7...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>comments</th>\n",
       "      <th>domains</th>\n",
       "      <th>links</th>\n",
       "      <th>points</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jane_brown</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(dwhsys.com)</td>\n",
       "      <td>https://dwhsys.com/2017/03/25/apache-zeppelin-...</td>\n",
       "      <td>23 points</td>\n",
       "      <td>Apache Zeppelin vs. Jupyter Notebook: comparis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ankit</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(udemy.com)</td>\n",
       "      <td>https://www.udemy.com/manipulate-excel-file-fr...</td>\n",
       "      <td>26 points</td>\n",
       "      <td>Automate Excel, Word, PDF, HTML Web Scraping f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kghamilton</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.com)</td>\n",
       "      <td>https://github.com/axibase/atsd-use-cases/blob...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Aging America: Modeling Birth Trends in the Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>maddad</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(knowtechie.com)</td>\n",
       "      <td>https://knowtechie.com/mobile-app-business-howto/</td>\n",
       "      <td>2 points</td>\n",
       "      <td>A 3-step guide to starting your mobile app bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>wilsstar007</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(packtpub.com)</td>\n",
       "      <td>https://datahub.packtpub.com/deep-learning/15-...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>15 Useful Python Libraries to make your Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>tmostak</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>https://www.mapd.com/blog/exploring-google-ana...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Exploring Google Analytics data with MapD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>drachenbach</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>https://drachenbach.github.io/blog/2018/03/12/...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>The Intuition behind Embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>eoberg</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/indeed-data-science/theres-...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Data Science job searching behavior - There's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>iheartai</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(aiworkbox.com)</td>\n",
       "      <td>https://www.aiworkbox.com/lessons/check-for-el...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Check For Element Wise Equality Between Two Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>summarizebotdev</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(summarizebot.com)</td>\n",
       "      <td>http://www.summarizebot.com/summarization_busi...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Natural language processing and web scraping API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>bon</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(arxiv.org)</td>\n",
       "      <td>https://arxiv.org/abs/1803.10768</td>\n",
       "      <td>2 points</td>\n",
       "      <td>The Unreasonable Effectivness of Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>bull</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(drivendata.org)</td>\n",
       "      <td>https://www.drivendata.org/competitions/</td>\n",
       "      <td>8 points</td>\n",
       "      <td>3 new comps for forecasting, anomalies and opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>kantord</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>https://kantord.github.io/just-dashboard/</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Just-dashboard: Create shareable interactive d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>e_ameisen</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/hero2vec-d...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Predicting e-sports winners with Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>hiimtomi</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://data36.com/create-table-sql/</td>\n",
       "      <td>2 points</td>\n",
       "      <td>How to Create a Table in SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>hiimtomi</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://data36.com/data-science-career-questio...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Is Data Science For You?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>hiimtomi</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(hackernoon.com)</td>\n",
       "      <td>https://hackernoon.com/aspiring-data-scientist...</td>\n",
       "      <td>14 points</td>\n",
       "      <td>Aspiring Data Scientists! Start to learn Stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>deeplearnting</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(deeplearningtrack.com)</td>\n",
       "      <td>https://www.deeplearningtrack.com/single-post/...</td>\n",
       "      <td>16 points</td>\n",
       "      <td>Setting up spark on google cloud made easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>bike_visual</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>(visualization.bike)</td>\n",
       "      <td>https://www.visualization.bike/</td>\n",
       "      <td>48 points</td>\n",
       "      <td>The most complete bike sharing visualization a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>albanotte</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(statsbot.co)</td>\n",
       "      <td>https://statsbot.co/blog/select-random-rows-sql/</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Scalable Select of Random Rows in SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>janvdp</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(zerotosingularity.com)</td>\n",
       "      <td>https://www.zerotosingularity.com/posts/course...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Running your Coursera (and all other) Jupyter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>dacod3r</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.com)</td>\n",
       "      <td>https://github.com/tmadl/sklearn-interpretable...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Simplified tree-based classifier &amp; regressor f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>andrewxhill</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sxsw.com)</td>\n",
       "      <td>https://schedule.sxsw.com/2018/events/PP73084</td>\n",
       "      <td>3 points</td>\n",
       "      <td>SXSW panel on offline data science, decentrali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>aldamiz</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(hackernoon.com)</td>\n",
       "      <td>https://hackernoon.com/how-we-grew-from-0-to-4...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Growing from 0 to 4M users on our fashion app ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>jameslee</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(statsbot.co)</td>\n",
       "      <td>https://statsbot.co/ltv-ebook</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Estimating customer lifetime value with SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>randyzwitch</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(randyzwitch.com)</td>\n",
       "      <td>http://randyzwitch.com/mapd-pjm-electricity-data/</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Getting Started With MapD, Part 2: Electricity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>zozozzzoya</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datalore.io)</td>\n",
       "      <td>https://blog.datalore.io/february-data-digest/</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Datalore's February Data Digest - on deep lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>mmq</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/polyaxon/jupyter-notebooks-...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Jupyter notebooks and tensorboard on Polyaxon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>wilsstar007</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(packtpub.com)</td>\n",
       "      <td>https://datahub.packtpub.com/ai/18-striking-ai...</td>\n",
       "      <td>13 points</td>\n",
       "      <td>18 striking AI Trends to watch in 2018 – Part 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>vimarshk</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/acing-ai/google-ai-intervie...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Google AI Interview Questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>marklit</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(marksblogg.com)</td>\n",
       "      <td>http://tech.marksblogg.com/billion-nyc-taxi-ri...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>1.1 Billion Taxi Rides with SQLite, Parquet &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>Crusso3</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(circonus.com)</td>\n",
       "      <td>https://www.circonus.com/2018/06/prometheus-ad...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Introducing the IRONdb Prometheus Adapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2</td>\n",
       "      <td>italosay</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.com)</td>\n",
       "      <td>https://github.com/Italosayan/P-P-P</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Spatiotemporal modeling with R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3</td>\n",
       "      <td>jukatan</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://data36.com/python-libraries-packages-d...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Python libraries and packages for Data Scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>randyzwitch</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>https://www.mapd.com/blog/scaling-pandas-to-th...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Scaling Pandas to the Billions with Ibis and MapD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5</td>\n",
       "      <td>jeremypmason</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/@plotlygraphs/introducing-p...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Introducing plotly.py 3.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>6</td>\n",
       "      <td>andrewxhill</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/textileio/tutorial-setting-...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Tutorial: Setting up an IPFS peer, part IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>7</td>\n",
       "      <td>randyzwitch</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>https://www.mapd.com/blog/announcing-mapd-4.0/</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Announcing MapD 4.0: Geospatial, Role-Based Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8</td>\n",
       "      <td>scotthajek</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(thenewstack.io)</td>\n",
       "      <td>https://thenewstack.io/the-good-bad-and-ugly-a...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>The Good, Bad and Ugly: Apache Spark for Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>9</td>\n",
       "      <td>analytics</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(statsbot.co)</td>\n",
       "      <td>https://statsbot.co/blog/data-team</td>\n",
       "      <td>6 points</td>\n",
       "      <td>How to balance the load on a data team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10</td>\n",
       "      <td>vimarshk</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/acing-ai/artificial-intelli...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Artificial Intelligence is the Bicycle for our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11</td>\n",
       "      <td>kromme</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(theanalyticslab.nl)</td>\n",
       "      <td>http://www.theanalyticslab.nl/2018/06/24/teleg...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Let R/Python send messages when the algorithms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>12</td>\n",
       "      <td>kmax12</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(towardsdatascience.com)</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Automated Feature Engineering in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>13</td>\n",
       "      <td>vimarshk</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/acing-ai/walmart-data-scien...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Walmart Data Science Interview Questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14</td>\n",
       "      <td>jukatan</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://courses.data36.com/p/the-junior-data-s...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>The Junior Data Scientist's First Month (Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>15</td>\n",
       "      <td>ddi_1</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(interviewqs.com)</td>\n",
       "      <td>https://www.interviewqs.com/</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Practice DS interview questions through email ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>outlace</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(outlace.com)</td>\n",
       "      <td>http://outlace.com/TensorNets1.html</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Tensor Networks and the Nature of Non-Linearity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>17</td>\n",
       "      <td>italosay</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.com)</td>\n",
       "      <td>https://github.com/nateraw/Lda2vec-Tensorflow</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Simple topic modeling using tensorflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>18</td>\n",
       "      <td>andrewxhill</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/textileio/decentralized-cod...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Decentralized code distribution for the future...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>19</td>\n",
       "      <td>flyelephant</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(flyelephant.net)</td>\n",
       "      <td>http://datasciencedigest.flyelephant.net/issue...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>DataScience Digest - Issue #13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>20</td>\n",
       "      <td>nanonets</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/nanonets/how-we-flew-a-dron...</td>\n",
       "      <td>12 points</td>\n",
       "      <td>How to easily automate Drone-based monitoring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>21</td>\n",
       "      <td>SharpSightLabs</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sharpsightlabs.com)</td>\n",
       "      <td>http://www.sharpsightlabs.com/blog/key-for-mas...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>A key for mastering data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>22</td>\n",
       "      <td>tbugaevskii</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://www.medium.com/data-science-school/pra...</td>\n",
       "      <td>26 points</td>\n",
       "      <td>Practical Apache Spark in 10 minutes. Part 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>23</td>\n",
       "      <td>asdasdas</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/nanonets/topic-modeling-wit...</td>\n",
       "      <td>19 points</td>\n",
       "      <td>How to easily do Topic Modeling with LSA, PSLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>24</td>\n",
       "      <td>e_ameisen</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Reinforcement Learning from scratch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>25</td>\n",
       "      <td>tbugaevskii</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://www.medium.com/activewizards-machine-l...</td>\n",
       "      <td>30 points</td>\n",
       "      <td>Top 7 Data Science Use Cases in Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>26</td>\n",
       "      <td>tbugaevskii</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://www.medium.com/activewizards-machine-l...</td>\n",
       "      <td>21 points</td>\n",
       "      <td>Top 20 R Libraries for Data Science in 2018 [I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>27</td>\n",
       "      <td>adam_alook</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(alookanalytics.com)</td>\n",
       "      <td>https://blog.alookanalytics.com/2018/06/11/geo...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Geolocated nearest neighbors in product campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>28</td>\n",
       "      <td>albanotte</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(statsbot.co)</td>\n",
       "      <td>https://statsbot.co/blog/bigquery-vs-redshift-...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>SQL queries to optimize BigQuery costs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>29</td>\n",
       "      <td>tanya</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(statsbot.co)</td>\n",
       "      <td>https://statsbot.co/blog/business-metrics-for-...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>The Complex Analytical Process to Define Busin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          authors    comments                     domains  \\\n",
       "0        0       jane_brown     discuss               (dwhsys.com)    \n",
       "1        1            ankit     discuss                (udemy.com)    \n",
       "2        2       kghamilton     discuss               (github.com)    \n",
       "3        3           maddad     discuss           (knowtechie.com)    \n",
       "4        4      wilsstar007     discuss             (packtpub.com)    \n",
       "5        5          tmostak     discuss                 (mapd.com)    \n",
       "6        6      drachenbach     discuss                (github.io)    \n",
       "7        7           eoberg   1 comment               (medium.com)    \n",
       "8        8         iheartai     discuss            (aiworkbox.com)    \n",
       "9        9  summarizebotdev     discuss         (summarizebot.com)    \n",
       "10      10              bon     discuss                (arxiv.org)    \n",
       "11      11             bull     discuss           (drivendata.org)    \n",
       "12      12          kantord     discuss                (github.io)    \n",
       "13      13        e_ameisen     discuss   (insightdatascience.com)    \n",
       "14      14         hiimtomi     discuss               (data36.com)    \n",
       "15      15         hiimtomi     discuss               (data36.com)    \n",
       "16      16         hiimtomi     discuss           (hackernoon.com)    \n",
       "17      17    deeplearnting   1 comment    (deeplearningtrack.com)    \n",
       "18      18      bike_visual  3 comments       (visualization.bike)    \n",
       "19      19        albanotte     discuss              (statsbot.co)    \n",
       "20      20           janvdp     discuss    (zerotosingularity.com)    \n",
       "21      21          dacod3r     discuss               (github.com)    \n",
       "22      22      andrewxhill     discuss                 (sxsw.com)    \n",
       "23      23          aldamiz     discuss           (hackernoon.com)    \n",
       "24      24         jameslee     discuss              (statsbot.co)    \n",
       "25      25      randyzwitch     discuss          (randyzwitch.com)    \n",
       "26      26       zozozzzoya     discuss              (datalore.io)    \n",
       "27      27              mmq     discuss               (medium.com)    \n",
       "28      28      wilsstar007     discuss             (packtpub.com)    \n",
       "29      29         vimarshk   1 comment               (medium.com)    \n",
       "..     ...              ...         ...                         ...   \n",
       "180      0          marklit     discuss           (marksblogg.com)    \n",
       "181      1          Crusso3     discuss             (circonus.com)    \n",
       "182      2         italosay     discuss               (github.com)    \n",
       "183      3          jukatan   1 comment               (data36.com)    \n",
       "184      4      randyzwitch  2 comments                 (mapd.com)    \n",
       "185      5     jeremypmason     discuss               (medium.com)    \n",
       "186      6      andrewxhill     discuss               (medium.com)    \n",
       "187      7      randyzwitch     discuss                 (mapd.com)    \n",
       "188      8       scotthajek   1 comment           (thenewstack.io)    \n",
       "189      9        analytics     discuss              (statsbot.co)    \n",
       "190     10         vimarshk     discuss               (medium.com)    \n",
       "191     11           kromme     discuss       (theanalyticslab.nl)    \n",
       "192     12           kmax12     discuss   (towardsdatascience.com)    \n",
       "193     13         vimarshk     discuss               (medium.com)    \n",
       "194     14          jukatan     discuss               (data36.com)    \n",
       "195     15            ddi_1     discuss          (interviewqs.com)    \n",
       "196     16          outlace     discuss              (outlace.com)    \n",
       "197     17         italosay     discuss               (github.com)    \n",
       "198     18      andrewxhill     discuss               (medium.com)    \n",
       "199     19      flyelephant     discuss          (flyelephant.net)    \n",
       "200     20         nanonets     discuss               (medium.com)    \n",
       "201     21   SharpSightLabs     discuss       (sharpsightlabs.com)    \n",
       "202     22      tbugaevskii     discuss               (medium.com)    \n",
       "203     23         asdasdas  2 comments               (medium.com)    \n",
       "204     24        e_ameisen     discuss   (insightdatascience.com)    \n",
       "205     25      tbugaevskii     discuss               (medium.com)    \n",
       "206     26      tbugaevskii     discuss               (medium.com)    \n",
       "207     27       adam_alook     discuss       (alookanalytics.com)    \n",
       "208     28        albanotte     discuss              (statsbot.co)    \n",
       "209     29            tanya     discuss              (statsbot.co)    \n",
       "\n",
       "                                                 links     points  \\\n",
       "0    https://dwhsys.com/2017/03/25/apache-zeppelin-...  23 points   \n",
       "1    https://www.udemy.com/manipulate-excel-file-fr...  26 points   \n",
       "2    https://github.com/axibase/atsd-use-cases/blob...   2 points   \n",
       "3    https://knowtechie.com/mobile-app-business-howto/   2 points   \n",
       "4    https://datahub.packtpub.com/deep-learning/15-...   7 points   \n",
       "5    https://www.mapd.com/blog/exploring-google-ana...   5 points   \n",
       "6    https://drachenbach.github.io/blog/2018/03/12/...   6 points   \n",
       "7    https://medium.com/indeed-data-science/theres-...   4 points   \n",
       "8    https://www.aiworkbox.com/lessons/check-for-el...   2 points   \n",
       "9    http://www.summarizebot.com/summarization_busi...   6 points   \n",
       "10                    https://arxiv.org/abs/1803.10768   2 points   \n",
       "11            https://www.drivendata.org/competitions/   8 points   \n",
       "12           https://kantord.github.io/just-dashboard/   5 points   \n",
       "13   https://blog.insightdatascience.com/hero2vec-d...   8 points   \n",
       "14                https://data36.com/create-table-sql/   2 points   \n",
       "15   https://data36.com/data-science-career-questio...   6 points   \n",
       "16   https://hackernoon.com/aspiring-data-scientist...  14 points   \n",
       "17   https://www.deeplearningtrack.com/single-post/...  16 points   \n",
       "18                     https://www.visualization.bike/  48 points   \n",
       "19    https://statsbot.co/blog/select-random-rows-sql/   2 points   \n",
       "20   https://www.zerotosingularity.com/posts/course...   7 points   \n",
       "21   https://github.com/tmadl/sklearn-interpretable...   7 points   \n",
       "22       https://schedule.sxsw.com/2018/events/PP73084   3 points   \n",
       "23   https://hackernoon.com/how-we-grew-from-0-to-4...   3 points   \n",
       "24                       https://statsbot.co/ltv-ebook   9 points   \n",
       "25   http://randyzwitch.com/mapd-pjm-electricity-data/   7 points   \n",
       "26      https://blog.datalore.io/february-data-digest/   4 points   \n",
       "27   https://medium.com/polyaxon/jupyter-notebooks-...   4 points   \n",
       "28   https://datahub.packtpub.com/ai/18-striking-ai...  13 points   \n",
       "29   https://medium.com/acing-ai/google-ai-intervie...   2 points   \n",
       "..                                                 ...        ...   \n",
       "180  http://tech.marksblogg.com/billion-nyc-taxi-ri...   2 points   \n",
       "181  https://www.circonus.com/2018/06/prometheus-ad...   2 points   \n",
       "182                https://github.com/Italosayan/P-P-P   3 points   \n",
       "183  https://data36.com/python-libraries-packages-d...   5 points   \n",
       "184  https://www.mapd.com/blog/scaling-pandas-to-th...   2 points   \n",
       "185  https://medium.com/@plotlygraphs/introducing-p...   2 points   \n",
       "186  https://medium.com/textileio/tutorial-setting-...   2 points   \n",
       "187     https://www.mapd.com/blog/announcing-mapd-4.0/   3 points   \n",
       "188  https://thenewstack.io/the-good-bad-and-ugly-a...   2 points   \n",
       "189                 https://statsbot.co/blog/data-team   6 points   \n",
       "190  https://medium.com/acing-ai/artificial-intelli...   2 points   \n",
       "191  http://www.theanalyticslab.nl/2018/06/24/teleg...   3 points   \n",
       "192  https://towardsdatascience.com/automated-featu...   5 points   \n",
       "193  https://medium.com/acing-ai/walmart-data-scien...   6 points   \n",
       "194  https://courses.data36.com/p/the-junior-data-s...   2 points   \n",
       "195                       https://www.interviewqs.com/   9 points   \n",
       "196                http://outlace.com/TensorNets1.html   4 points   \n",
       "197      https://github.com/nateraw/Lda2vec-Tensorflow   5 points   \n",
       "198  https://medium.com/textileio/decentralized-cod...   3 points   \n",
       "199  http://datasciencedigest.flyelephant.net/issue...   9 points   \n",
       "200  https://medium.com/nanonets/how-we-flew-a-dron...  12 points   \n",
       "201  http://www.sharpsightlabs.com/blog/key-for-mas...   3 points   \n",
       "202  https://www.medium.com/data-science-school/pra...  26 points   \n",
       "203  https://medium.com/nanonets/topic-modeling-wit...  19 points   \n",
       "204  https://blog.insightdatascience.com/reinforcem...   8 points   \n",
       "205  https://www.medium.com/activewizards-machine-l...  30 points   \n",
       "206  https://www.medium.com/activewizards-machine-l...  21 points   \n",
       "207  https://blog.alookanalytics.com/2018/06/11/geo...   5 points   \n",
       "208  https://statsbot.co/blog/bigquery-vs-redshift-...   4 points   \n",
       "209  https://statsbot.co/blog/business-metrics-for-...   6 points   \n",
       "\n",
       "                                                titles  \n",
       "0    Apache Zeppelin vs. Jupyter Notebook: comparis...  \n",
       "1    Automate Excel, Word, PDF, HTML Web Scraping f...  \n",
       "2    Aging America: Modeling Birth Trends in the Un...  \n",
       "3    A 3-step guide to starting your mobile app bus...  \n",
       "4    15 Useful Python Libraries to make your Data S...  \n",
       "5            Exploring Google Analytics data with MapD  \n",
       "6                      The Intuition behind Embeddings  \n",
       "7    Data Science job searching behavior - There's ...  \n",
       "8    Check For Element Wise Equality Between Two Py...  \n",
       "9     Natural language processing and web scraping API  \n",
       "10      The Unreasonable Effectivness of Deep Learning  \n",
       "11   3 new comps for forecasting, anomalies and opt...  \n",
       "12   Just-dashboard: Create shareable interactive d...  \n",
       "13   Predicting e-sports winners with Machine Learning  \n",
       "14                        How to Create a Table in SQL  \n",
       "15                            Is Data Science For You?  \n",
       "16   Aspiring Data Scientists! Start to learn Stati...  \n",
       "17          Setting up spark on google cloud made easy  \n",
       "18   The most complete bike sharing visualization a...  \n",
       "19               Scalable Select of Random Rows in SQL  \n",
       "20   Running your Coursera (and all other) Jupyter ...  \n",
       "21   Simplified tree-based classifier & regressor f...  \n",
       "22   SXSW panel on offline data science, decentrali...  \n",
       "23   Growing from 0 to 4M users on our fashion app ...  \n",
       "24         Estimating customer lifetime value with SQL  \n",
       "25   Getting Started With MapD, Part 2: Electricity...  \n",
       "26   Datalore's February Data Digest - on deep lear...  \n",
       "27       Jupyter notebooks and tensorboard on Polyaxon  \n",
       "28     18 striking AI Trends to watch in 2018 – Part 1  \n",
       "29                       Google AI Interview Questions  \n",
       "..                                                 ...  \n",
       "180  1.1 Billion Taxi Rides with SQLite, Parquet & ...  \n",
       "181          Introducing the IRONdb Prometheus Adapter  \n",
       "182                     Spatiotemporal modeling with R  \n",
       "183  Python libraries and packages for Data Scienti...  \n",
       "184  Scaling Pandas to the Billions with Ibis and MapD  \n",
       "185                        Introducing plotly.py 3.0.0  \n",
       "186         Tutorial: Setting up an IPFS peer, part IV  \n",
       "187  Announcing MapD 4.0: Geospatial, Role-Based Pe...  \n",
       "188  The Good, Bad and Ugly: Apache Spark for Data ...  \n",
       "189             How to balance the load on a data team  \n",
       "190  Artificial Intelligence is the Bicycle for our...  \n",
       "191  Let R/Python send messages when the algorithms...  \n",
       "192            Automated Feature Engineering in Python  \n",
       "193           Walmart Data Science Interview Questions  \n",
       "194  The Junior Data Scientist's First Month (Class...  \n",
       "195  Practice DS interview questions through email ...  \n",
       "196    Tensor Networks and the Nature of Non-Linearity  \n",
       "197             Simple topic modeling using tensorflow  \n",
       "198  Decentralized code distribution for the future...  \n",
       "199                     DataScience Digest - Issue #13  \n",
       "200  How to easily automate Drone-based monitoring ...  \n",
       "201                   A key for mastering data science  \n",
       "202       Practical Apache Spark in 10 minutes. Part 2  \n",
       "203  How to easily do Topic Modeling with LSA, PSLA...  \n",
       "204                Reinforcement Learning from scratch  \n",
       "205            Top 7 Data Science Use Cases in Finance  \n",
       "206  Top 20 R Libraries for Data Science in 2018 [I...  \n",
       "207  Geolocated nearest neighbors in product campai...  \n",
       "208             SQL queries to optimize BigQuery costs  \n",
       "209  The Complex Analytical Process to Define Busin...  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, numpy as np\n",
    "\n",
    "def parse_url(url=\"http://www.datatau.com\", data=False):\n",
    "    \n",
    "    response  =  requests.get(url)\n",
    "    links     =  Selector(text=response.text).xpath(\"//td[@class='title']/a/@href\").extract()\n",
    "    titles    =  Selector(text=response.text).xpath(\"//td[@class='title']/a/text()\").extract()\n",
    "    points    =  Selector(text=response.text).xpath(\"//td[@class='subtext']/span/text()\").extract()\n",
    "    domains   =  Selector(text=response.text).xpath(\"//td[@class='title']/span/text()\").extract()\n",
    "    authors   =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'user')]/text()\").extract()\n",
    "    comments  =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'item')]/text()\").extract()\n",
    "\n",
    "    expected_length = 30\n",
    "    \n",
    "    # Add [np.nan]*(expected_length - len(points)) to \n",
    "    # the end of the lists. It will fill in missing\n",
    "    # values that sometimes don't exist at the end of the results.\n",
    "    scraped = dict(\n",
    "        titles   =  titles[:30], \n",
    "        links    =  links[:30], # :30 because of that \"more\" link.\n",
    "        points   =  points + [np.nan]*(expected_length - len(points)),\n",
    "        domains  =  domains + [np.nan]*(expected_length - len(domains)),\n",
    "        authors  =  authors + [np.nan]*(expected_length - len(authors)),\n",
    "        comments =  comments + [np.nan]*(expected_length - len(comments))\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(scraped)\n",
    "    \n",
    "    if type(data) != bool:\n",
    "        data = df.append(data)\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    # If there's data, append them. \n",
    "    # If not, it's the first iteration so there's no need.\n",
    "    # Find \"more\" link.\n",
    "    more_anchor  =  Selector(text=response.text).xpath(\"//a[text() = 'More']/@href\").extract()\n",
    "    \n",
    "    if len(more_anchor) > 0:\n",
    "        more_url  =  \"http://www.datatau.com%s\" % more_anchor[0]\n",
    "        print \"Fetching %s...\" % more_url\n",
    "        return parse_url(more_url, data=data)\n",
    "    else:\n",
    "        return data.reset_index()\n",
    "       \n",
    "        \n",
    "df = parse_url(\"http://www.datatau.com\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
